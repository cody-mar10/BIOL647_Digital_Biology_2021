# #+TITLE: Digital Biology
#+AUTHOR: Rodolfo Aramayo
#+EMAIL: raramayo@tamu.edu
#+STARTUP: align
* *Introduction to RNASeq*
** *[[.//00Data/T14Data/01_Seq_strategies_new.pdf][Practical Strategies for Sequencing]]*           
** *[[.//00Data/T14Data/02_RNASeq_Lib_prep.pdf][RNASeq Library Preparation]]*                    
** *General Outline*
  | [[./00Data/T14Data/outline.png]] |
** *Introduction_to_ Experimental_design*
  :PROPERTIES:
  :CUSTOM_ID: introduction_to_ Experimental_design
  :END:
+ Keep it simple
  + Classical experimental design example:
    + Developmental time course experiment (Time series)
    + Without missing values, where possible
    + Intended analysis must be feasbile – can the available samples and hypothesis of interest be
      combined to formulate a testable statistical hypothesis?
+ Include Replicates
  + Extent of replication determines nuance of biological question
  + No replication (1 sample per treatment) really limits what you can say and therefore gives you
    limited statistical options
  + Include at least 3 if not more (6 is best) replicates per treatment
  + Would you be able to detect 2-fold change in average expression between groups?
  + Number of replicates varies by experiment:
    + 10-50 replicates per treatment for population studies, e.g., cancer cell lines
    + 1000’s of replicates for prospective studies, e.g., SNP discovery
+ Important: Avoid confounding experimental factors with other factors
  + Common problems:
    + samples from one treatment all on the same flow cell
    + samples from treatment 1 processed first, treatment 2 processed second, etc
+ Record co-variates
+ Take into consideration Surrogate Variable Analysis
  + [[http://www.nature.com/nrg/journal/v11/n10/abs/nrg2825.html][Leek et al., 2010, Nature Reviews Genetics 11 733-739]]
  + [[http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161][Leek & Story PLoS Genet 3(9): e161]]
    + Scientific finding: pervasive batch effects
    + Statistical insights: surrogate variable analysis: identify and build surrogate variables;
      remove known batch effects
    + Benefits: reduce dependence, stabilize error rate estimates, and improve reproducibility
+ In Wet Lab Experiments:
  + Record or avoid confounding factors in experimental design
  + Avoid artifacts of your particular protocols:
    + Sequence contaminants
    + Enrichment bias, e.g., non-uniform transcript representation.
    + PCR artifacts – adapter contaminants, sequence-specific amplification bias, ...
+ In Sequencing Experiments:
  + Axes of variation
    + Single- versus paired-end
    + Length: 50-200nt
    + Number of reads per sample
+ Application-specific, e.g.,
  + ChIP-seq: short, single-end reads are usually sufficient
  + RNA-seq, known genes: single- or paired-end reads
  + RNA-seq, transcripts or novel variants: paired-end reads
  + Copy number: single- or paired-end reads
  + Structural variants: paired-end reads
  + Variants: depth via longer, paired-end reads
  + Microbiome: long paired-end reads (overlapping ends)
+ In Alignment:
  + Alignment strategies
    + /de novo/
    + No reference genome; considerable sequencing and computational resources
    + Genome
    + Established reference genome
    + Splice-aware aligners
    + Novel transcript discovery
    + Transcriptome
    + Established reference genome; reliable gene model
    + Known gene / transcript expression
    + Simple aligners
      + Use known gene model to count aligned reads overlapping regions of interest/gene models
      + Gene model can be public (e.g., UCSC, NCBI, ENSEMBL) or /ad hoc/ (gff file)
+ [[http://www.nature.com/nature/journal/v492/n7428/full/492180a.html][Research methods: Know when your numbers are significant]]
+ [[http://www.nature.com/nature/journal/v492/n7428/fig_tab/492180a_T1.html][Statistics glossary: Some common statistical concepts and their uses in analysing experimental results]]
+ [[http://rnajournal.cshlp.org/content/early/2016/03/28/rna.053959.115][How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use?]]
+ [[https://www.youtube.com/watch?v=gKnfP2_Xdpo&feature=youtu.be][RNA-seq - the problem with technical replicates]] 
** *Experimental Design Considerations*
  :PROPERTIES:
  :CUSTOM_ID: experimental-design-considerations
  :END:

  Understanding the steps in the experimental process of RNA extraction
  and preparation of RNA-Seq libraries is helpful for designing an RNA-Seq
  experiment, but there are special considerations that should be
  highlighted that can greatly affect the quality of a differential
  expression analysis.
  
  These important considerations include:
  
  1. Number and type of *replicates*
  2. Avoiding *confounding*
  3. Addressing *batch effects*
  
  We will go over each of these considerations in detail, discussing best
  practice and optimal design.
  
*** Replicates
   :PROPERTIES:
   :CUSTOM_ID: replicates
   :END:

   Experimental replicates can be performed as *technical replicates* or *biological replicates*.
   | [[./00Data/T14Data/replicates.png]] |
   /Image credit: [[https://dx.doi.org/10.15252/embj.201592958][Klaus B.,EMBO J (2015) *34*: 2727-2730]]/
   
   - *Technical replicates:* use the same biological sample to repeat the
     technical or experimental steps in order to accurately measure
     technical variation and remove it during analysis.
   
   - *Biological replicates* use different biological samples of the same
     condition to measure the biological variation between samples.
   
   In the days of microarrays, technical replicates were considered a
   necessity; however, with the current RNA-Seq technologies, technical
   variation is much lower than biological variation and *technical
   replicates are unneccessary*.
   
   In contrast, *biological replicates are absolutely essential*. For
   differential expression analysis, the more biological replicates, the
   better the estimates of biological variation and the more precise our
   estimates of the mean expression levels. This leads to more accurate
   modeling of our data and identification of more differentially expressed
   genes.
   
*** Confounding
   :PROPERTIES:
   :CUSTOM_ID: confounding
   :END:

   A confounded RNA-Seq experiment is one where you *cannot distinguish the
   separate effects of two different sources of variation* in the data.
   
   For example, we know that sex has large effects on gene expression, and
   if all of our /control/ mice were female and all of the /treatment/ mice
   were male, then our treatment effect would be confounded by sex. *We
   could not differentiate the effect of treatment from the effect of sex.*
   | [[./00Data/T14Data/confounded_design.png]] |
   
   *To AVOID confounding:*
   
   - Ensure animals in each condition are all the *same sex, age, litter,
     and batch*, if possible.
   
   - If not possible, then ensure to split the animals equally between
     conditions
     | [[./00Data/T14Data/non_confounded_design.png]] |
   
*** Batch effects
   :PROPERTIES:
   :CUSTOM_ID: batch-effects
   :END:
   
   Batch effects are a significant issue for RNA-seq analyses, since you
   can see significant differences in expression due solely to batch.
   | [[./00Data/T14Data/batch_effect_pca.png]] |
   /Image credit: [[https://www.biorxiv.org/content/early/2015/08/25/025528][Hicks SC, etal., bioRxiv (2015)]]/
   
**** How to know whether you have batches?
    :PROPERTIES:
    :CUSTOM_ID: how-to-know-whether-you-have-batches
    :END:
    
    - Were all RNA isolations performed on the same day?
    
    - Were all library preparations performed on the same day?
    
    - Did the same person perform the RNA isolation/library preparation for
      all samples?
    
    - Did you use the same reagents/kits for all samples?
    
    - Did you perform the RNA isolation/library preparation in the same
      location?
    
    If /any/ of the answers is *No*, then you have batches.
    
**** Best practices regarding batches:
    :PROPERTIES:
    :CUSTOM_ID: best-practices-regarding-batches
    :END:
    
    - Design the experiment from start to finish to *avoid batches*, if
      possible. If unsure of what can bring in a batch effect, talk with a
      biostats consultant before starting experiment.
    
    - If unable to avoid batches:
    
      - *Do NOT confound* your experiment by batch:
        | [[./00Data/T14Data/confounded_batch.png]] |
        /Image credit: [[https://www.biorxiv.org/content/early/2015/08/25/025528][Hicks SC, et al., bioRxiv (2015)]]/
    
      - *DO* split replicates of the different sample groups across batches.
        The more replicates the better (definitely 3 or more).
        | [[./00Data/T14Data/batch_effect.png]] |
        /Image credit: [[https://www.biorxiv.org/content/early/2015/08/25/025528][Hicks SC, et al., bioRxiv (2015)]]/
    
      - *DO* include batch information in your *experimental metadata*.
        During the analysis, we can regress out the variation due to batch
        so it doesn't affect our results if we have that information.
        | [[./00Data/T14Data/metadata_batch.png]] |
** *Experimental Replicates*
  | [[./00Data/T14Data/de_replicates_img.png]] |
  /Image credit: [[https://doi.org/10.1093/bioinformatics/btt688][Liu, Y.,et al., Bioinformatics (2014) *30*(3): 301-304]]/
  
  As the figure above illustrates, *biological replicates are of greater
  importance than sequencing depth*. The figure shows the relationship
  between sequencing depth and number of replicates on the number of
  differentially expressed genes  [[https://academic.oup.com/bioinformatics/article/30/3/301/228651/RNA-seq-differential-expression-studies-more][identified]].

  Note that an *increase in the number of replicates tends to return more
  DE genes than increasing the sequencing depth*. Therefore, generally
  more replicates are better than higher sequencing depth, with the caveat
  that higher depth is required for detection of lowly expressed DE genes
  and for performing isoform-level differential expression.
  
  Replicates are almost always preferred to greater sequencing depth for
  bulk RNA-Seq. However, guidelines depend on the experiment performed and
  the desired analysis. Below we list some general guidelines for
  replicates and sequencing depth to help with experimental planning:
  
  - *General gene-level differential expression:*
  
    - [[https://www.encodeproject.org/documents/cede0cbe-d324-4ce7-ace4-f0c3eddf5972/@@download/attachment/ENCODE%20Best%20Practices%20for%20RNA_v2.pdf][ENCODE guidelines]] suggest 30 million SE reads per sample (stranded).
  
    - 15 million reads per sample is often sufficient, if there are at
      least 4 replicates.
  
    - More replicates >> More sequencing depth
  
  - *Gene-level differential expression with detection of lowly-expressed
    genes:*
  
    - Sequence deeper with at least 30-60 million reads depending on level
      of expression (start with 30 million with a good number of
      replicates).
  
    - Similarly benefits from replicates more than sequencing depth.
  
  - *Splice-isoform differential expression:*
  
    - For known isoforms, suggested to have a depth of at least 30 million
      reads per sample and paired-end reads.
  
    - For novel isoforms should have more depth (> 60 million reads per
      sample).
  
    - Choose biological replicates over paired/deeper sequencing.
  
  - *Other types of RNA analyses (intron retention, small RNA-Seq, etc.):*
  
    - Different recommendations depending on the analysis.
  
    - Almost always more biological replicates are better!
** *Count Modeling and Hypothesis*
*** Count modeling and Hypothesis testing
   :PROPERTIES:
   :CUSTOM_ID: count-modeling-and-hypothesis-testing
   :END:
   
   Once the count data is filtered, the next step is to perform the
   differential expression analysis.
   | [[./00Data/T14Data/deseq_workflow_full.png]] |
   Internally, DESeq2 is performing a number of steps but here we will
   focus on describing the count modeling and hypothesis testing. Modeling
   is a mathematically formalized way to approximate how the data behaves
   given a set of parameters.
   
*** Characteristics of RNA-seq count data
   :PROPERTIES:
   :CUSTOM_ID: characteristics-of-rna-seq-count-data
   :END:
   
   To determine the appropriate statistical model, we need information
   about the distribution of counts. To get an idea about how RNA-seq
   counts are distributed, we can plot the counts for a single sample:
   | [[./00Data/T14Data/deseq_counts_distribution.png]] |
   If we *zoom in close to zero*, we can see that there are a large number
   of genes with counts of zero:
   | [[./00Data/T14Data/deseq_counts_distribution_zoomed.png]] |
   These images illustrate some common features of RNA-seq count data:
   
   - a *low number of counts associated with a large proportion of genes*
   - a long right tail due to the *lack of any upper limit for expression*
   - large dynamic range
   
   #+BEGIN_QUOTE
     *NOTE:* The log intensities of the microarray data approximate a
     normal distribution. However, due to the different properties of the
     of RNA-seq count data, such as integer counts instead of continuous
     measurements and non-normally distributed data, the normal
     distribution does not accurately model RNA-seq counts [[[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3541212/][PMC3541212]]].
   #+END_QUOTE
   
**** Choosing an appropriate statistical model
    :PROPERTIES:
    :CUSTOM_ID: choosing-an-appropriate-statistical-model
    :END:
    
    Count data in general can be modeled with various distributions:
    
    1. *Binomial distribution:* Gives you the *probability of getting a
       number of heads upon tossing a coin a number of times*. Based on
       discrete events and used in situations when you have a certain number
       of cases.
    
    2. *Poisson distribution:* For use, when *the number of cases is very
       large (i.e. people who buy lottery tickets), but the probability of
       an event is very small (probability of winning)*. The Poisson is
       similar to the binomial, but is based on continuous events.
       Appropriate for data where mean == variance.
    
    3. *Negative binomial distribution:* An approximation of the Poisson,
       but has an additional parameter that adjusts the variance
       independently from the mean.
    
    #+BEGIN_QUOTE
      [[https://youtu.be/fxtB8c3u6l8][Details provided by Rafael Irizarry in the EdX class.]]
    #+END_QUOTE
    
***** So what do we use for RNA-seq count data?
     :PROPERTIES:
     :CUSTOM_ID: so-what-do-we-use-for-rna-seq-count-data
     :END:
     
     With RNA-Seq data, *a very large number of RNAs are represented and the
     probability of pulling out a particular transcript is very small*. Thus,
     it would be an appropriate situation to use the Poisson or Negative
     binomial distribution. Choosing one over the other *will depend on the
     relationship between mean and variance in our data*.
     
*** Mean versus Variance
   :PROPERTIES:
   :CUSTOM_ID: mean-versus-variance
   :END:
   
   In the figure below we have plotted the mean against the variance for
   three replicate samples in a study. Each data point represents a gene
   and the red line represents x = y.
   | [[./00Data/T14Data/deseq_mean_vs_variance.png]] |
   There's two things to note here:
   
   1. The *variance across replicates tends to be greater than the mean*
      (red line), especially for genes with large mean expression levels.
   2. For the *lowly expressed genes* we see quite a bit of scatter. We
      usually refer to this as "heteroscedasticity". That is, for a given
      expression level we observe *a lot of variation in the amount of
      variance*.
   
   /This is a good indication that our data do not fit the Poisson
   distribution./ If the proportions of mRNA stayed exactly constant
   between the biological replicates for a sample group, we could expect
   Poisson distribution (where mean == variance). Alternatively, if we
   continued to add more replicates (i.e. > 20) we should eventually see
   the scatter start to reduce and the high expression data points move
   closer to the red line. So in theory, of we had enough replicates we
   could use the Poisson.
   
   However, in practice a large number of replicates can be either hard to
   obtain (depending on how samples are obtained) and/or can be
   unaffordable. It is more common to see datasets with only a handful of
   replicates (~3-5) and reasonable amount of variation between them. The
   model that fits best, given this type of variability between replicates,
   is the Negative Binomial (NB) model. Essentially, *the NB model is a
   good approximation for data where the mean < variance*, as is the case
   with RNA-Seq count data.
   
   #+BEGIN_QUOTE
     *NOTE:* If we use the Poisson this will underestimate variability
     leading to an increase in false positive DE genes.
   #+END_QUOTE
   
*** Tools for gene-level differential expresssion analysis
   :PROPERTIES:
   :CUSTOM_ID: tools-for-gene-level-differential-expresssion-analysis
   :END:
   
   There are a number of software packages that have been developed for
   differential expression analysis of RNA-seq data. Many studies
   describing comparisons between these methods show that while there is
   some concordance in the genes that are identified as differentially
   expressed, there is also much variability between tools. 
   
   *Additionally, there is no one method that performs optimally under all conditions ([[https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-91][Soneson and Dleorenzi, 2013]]).*
   | [[./00Data/T14Data/deg_methods1.png]] | [[./00Data/T14Data/deg_methods2.png]] |
   Even as new methods are continuously being developed, there are a select
   few that are generally recommended as best practice. Here, we list and
   describe three of those: DESeq2, edgeR and Limma-voom.
   
   *[[https://bioconductor.org/packages/release/bioc/html/DESeq2.html][DESeq2]]* and *[[https://bioconductor.org/packages/release/bioc/html/edgeR.html][EdgeR]]* both use the negative binomial model, employ
   similar methods, and typically, yield similar results. They are both
   pretty stringent, and have a good balance between sensitivity and
   specificity (reducing both false positives and false
   negatives). DESeq2 does have soem extra features which implement
   various levels of filtering and shrinkage of fold changes to account
   for the heteroscedasticity described above.
   
   *[[https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29][Limma-Voom]]* is another set of tools often used together for DE
   analysis. The Limma package was initially developed for mircroarray
   data where data is normally distributed. The =voom= functionality was
   introduced more recently to allow for the analysis of RNA-seq count
   data. Essentially weights are computed and applied to the count
   matrix, transforming data such that it is normally distributed and
   Limma functions can be applied.  bThis method can be less sensitive
   for small sample sizes, and is recommended when the number of
   biological replicates per group grows large (> 20).
   
*** Tools for transcript-level differential expression analysis
   :PROPERTIES:
   :CUSTOM_ID: tools-for-transcript-level-differential-expression-analysis
   :END:
   
   Until this point we have focused on looking for expression changes at
   the gene-level. If you are interested in looking at *splice isoform
   expression changes between groups*, not that the previous methods (i.e
   DESeq2) will not work. To demonstrate how to identify transcript-level
   differential expression we will describe a tool called *Sleuth*.
   
   [[http://pachterlab.github.io/sleuth/][Sleuth]] is a fast, lightweight tool that uses transcript abundance
   estimates output from *pseudo-alignment* algorithms that use
   *bootstrap sampling*, such as Sailfish, Salmon, and Kallisto, to
   perform differential expression analysis of gene isoforms. Sleuth
   accounts for this technical variability by using *bootstraps as a
   proxy for technical replicates*, which are used to model the technical
   variability in the abundance estimates. Bootstrapping essentially
   *calculates the abundance estimates for all genes using a different
   sub-sample of reads* during each round of bootstrapping. The variation
   in the abundance estimates output from each round of bootstrapping is
   used for the estimation of the technical variance for each gene.
   
   #+BEGIN_QUOTE
     More information about the theory/process for sleuth is available in
     the [[https://www.nature.com/articles/nmeth.4324][Nature Methods paper]], this [[https://liorpachter.wordpress.com/2015/08/17/a-sleuth-for-rna-seq/][blogpost]] and step-by-step tutorials
     are available on the [[https://pachterlab.github.io/sleuth/walkthroughs][sleuth website]].
   #+END_QUOTE
   
   #+BEGIN_QUOTE
     *NOTE:* /Kallisto is distributed under a non-commercial license,
     while Sailfish and Salmon are distributed under the [[http://www.gnu.org/licenses/gpl.html][GNU General Public License, version 3]]./
   #+END_QUOTE
   
*** Hypothesis testing
   :PROPERTIES:
   :CUSTOM_ID: hypothesis-testing
   :END:
   
   With differential expression analysis, we are looking for
   genes/transcripts that change in expression between two or more groups,
   for example:
   
   - case vs. control
   - treated vs. untreated
   - series of time points
   
   *Why does it not work to identify differentially expressed genes by ranking the genes by how different they are between the two groups (based on fold change values)?*
   | [[./00Data/T14Data/de_variation.png]] |
   Because, more often than not *there is much more going on with your data
   than what you are anticipating*. The goal of differential expression
   analysis to determine the relative role of these effects, and to
   separate the "interesting" from the "uninteresting".
   | [[./00Data/T14Data/de_norm_counts_var.png]] |
   For each gene, we are assessing whether the differences in expression
   (counts) between groups is significant given the amount of variation
   observed within groups (replicates).
   
   First, for each gene we set up a *null hypothesis*, which in our case is
   that *there is no differential expression across the two sample groups*.
   Notice that we can do this without observing any data, because it is
   based on a thought experiment. Second, we *use a statistical test* to
   determine if based on the observed data, *the null hypothesis is true*.
   
**** Pairwise comparisons using the Wald test
    :PROPERTIES:
    :CUSTOM_ID: pairwise-comparisons-using-the-wald-test
    :END:
    
    For RNA-seq, the Wald test is commonly used for hypothesis testing when
    comparing two groups. Based on the model fit (taking into account the
    "uninteresting" the best we can), *coefficients* are estimated for each
    gene/transcript and are *used to test differences between two groups.* A
    Wald test statistic is computed along with a probability that a test
    statistic at least as extreme as the observed value were selected at
    random. This probability is called the p-value of the test. *If the
    p-value is small we reject the null hypothesis* and state that there is
    evidence against the null *(i.e. the gene is differentially expressed)*.
    
**** Likelihood Ratio Test (LRT) for multiple levels/time series
    :PROPERTIES:
    :CUSTOM_ID: likelihood-ratio-test-lrt-for-multiple-levelstime-series
    :END:
    
    For experimental designs in which you have more than two sample groups,
    other statistical tests exist. For these types of comparisons, we are
    interested in *identifying genes that show any expression change across
    the sample groups that we are investigating*. Once we have identified
    those significant genes, *post-hoc clustering* can be applied to find
    groups of genes that share similar expression profiles.
    | [[./00Data/T14Data/mov10_clusters.png]] |
    In the *DESeq2* package, the *Likelihood Ratio Test (LRT)* is
    implemented for the analayis of data in which there are more than two
    sample groups. This type of test can be especially useful in analyzing
    time course experiments. The LRT requires the user to identify a full
    model (the main effect plus all covariates) and a reduced model (the
    full mode without the main effect variable). The full model is then
    compared to the reduced model using and Analysis of Deviance (ANODEV),
    which is essentially *testing whether the term(s) removed in the
    'reduced' model explains a significant amount of variation in the data.*
    
    #+BEGIN_QUOTE
      *NOTE:* Generally, this test will result in a larger number of genes
      than the individual pair-wise comparisons. While the LRT is a test of
      significance for differences of any level of the factor, one should
      not expect it to be exactly equal to the union of sets of genes using
      Wald tests (although we do expect a majority overlap).
    #+END_QUOTE
    
*** Multiple test correction
   :PROPERTIES:
   :CUSTOM_ID: multiple-test-correction
   :END:
   
   From a statistical point of view, for each gene we are testing the null
   hypothesis that there is no differential expression across the sample
   groups. This may represent thousands of tests. The more genes we test,
   the more we inflate the false positive rate. *This is the multiple
   testing problem.*
   
   For example, the p-value with a significance cut-off of 0.05 means there
   is a 5% chance of error. If we test 20,000 genes for differential
   expression, at p < 0.05 we would expect to find 1,000 genes by chance.
   If we found 3000 genes to be differentially expressed total, roughly one
   third of our genes are false positives. We would not want to sift
   through our "significant" genes to identify which ones are true
   positives.
   
   There are a few commonly used approaches to correcting for this problem:
   
   - *Bonferroni:* The adjusted p-value is calculated by: p-value * m (m =
     total number of tests). *This is a very conservative approach with a
     high probability of false negatives*, so is generally not recommended.
   - *FDR/Benjamini-Hochberg:* Benjamini and Hochberg (1995) defined the
     concept of FDR and created an algorithm to control the expected FDR
     below a specified level given a list of independent p-values. *An
     interpretation of the BH method for controlling the FDR is implemented
     in DESeq2 in which we rank the genes by p-value, then multiply each
     ranked p-value by m/rank*.
   - *Q-value / Storey method:* The minimum FDR that can be attained when
     calling that feature significant. For example, if gene X has a q-value
     of 0.013 it means that 1.3% of genes that show p-values at least as
     small as gene X are false positives
   
   #+BEGIN_QUOTE
     *So what does FDR < 0.05 mean?* The most commonly used method is the
     FDR. By setting the FDR cutoff to < 0.05, we're saying that the
     proportion of false positives we expect amongst our differentially
     expressed genes is 5%. For example, if you call 500 genes as
     differentially expressed with an FDR cutoff of 0.05, you expect 25 of
     them to be false positives.
   #+END_QUOTE
** *Analysis Workflow*
  :PROPERTIES:
  :CUSTOM_ID: analysis-workflow
  :END:
  
  The goal of RNA-seq is often to perform differential expression
  testing to determine which genes or transcripts are expressed at
  different levels between conditions. These findings can offer
  biological insight into the processes affected by the condition(s) of
  interest. Below is an overview of the analysis workflow that is
  followed for differential gene expression analysis with bulk RNA-seq
  data.
  | [[./00Data/T14Data/full_workflow_2019.png]] |
*** QC on sequencing data
   :PROPERTIES:
   :CUSTOM_ID: qc-on-sequencing-data
   :END:
   
   The first step in the RNA-Seq workflow is to take the FASTQ files
   received from the sequencing facility and assess the quality of the
   reads.
   
**** Unmapped read data (FASTQ)
    :PROPERTIES:
    :CUSTOM_ID: unmapped-read-data-fastq
    :END:
    
    The [[https://en.wikipedia.org/wiki/FASTQ_format][FASTQ]] file format is the defacto file format for sequence reads
    generated from next-generation sequencing technologies. This file
    format evolved from FASTA in that it contains sequence data, but also
    contains quality information. Similar to FASTA, the FASTQ file begins
    with a header line.  The difference is that the FASTQ header is
    denoted by a =@= character.  For a single record (sequence read) there
    are four lines, each of which are described below:
    
    | Line | Description                                                                                                  |
    |------+--------------------------------------------------------------------------------------------------------------|
    |    1 | Always begins with '@' and then information about the read                                                   |
    |    2 | The actual DNA sequence                                                                                      |
    |    3 | Always begins with a '+' and sometimes the same info in line 1                                               |
    |    4 | Has a string of characters which represent the quality scores; must have same number of characters as line 2 |
    
    Let's use the following read as an example:
    
    #+BEGIN_EXAMPLE
      @HWI-ST330:304:H045HADXX:1:1101:1111:61397
      CACTTGTAAGGGCAGGCCCCCTTCACCCTCCCGCTCCTGGGGGANNNNNNNNNNANNNCGAGGCCCTGGGGTAGAGGGNNNNNNNNNNNNNNGATCTTGG
      +
      @?@DDDDDDHHH?GH:?FCBGGB@C?DBEGIIIIAEF;FCGGI#########################################################
    #+END_EXAMPLE
    
    As mentioned previously, line 4 has characters encoding the quality of
    each nucleotide in the read. The legend below provides the mapping of
    quality scores (Phred-33) to the quality encoding characters. Different
    quality encoding scales exist (differing by offset in the ASCII table),
    but note the most commonly used one is fastqsanger.
    
    #+BEGIN_EXAMPLE
      Quality encoding: !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHI
                        |         |         |         |         |
         Quality score: 0........10........20........30........40                                
    #+END_EXAMPLE
    
    Each quality score represents the probability that the corresponding
    nucleotide call is incorrect. This quality score is logarithmically
    based and is calculated as:
    
    #+BEGIN_EXAMPLE
      Q = -10 x log10(P), where P is the probability that a base call is erroneous
    #+END_EXAMPLE
    
    These probability values are assigned by the base calling algorithm. The
    score values can be interpreted as follows:
    
    | Phred Quality Score | Probability of incorrect base call | Base call accuracy |
    |---------------------+------------------------------------+--------------------|
    |                  10 | 1 in 10                            |                90% |
    |                  20 | 1 in 100                           |                99% |
    |                  30 | 1 in 1000                          |              99.9% |
    |                  40 | 1 in 10,000                        |             99.99% |
    
    Therefore, for the first nucleotide in the read (C), there is less than
    a 1 in 1000 chance that the base was called incorrectly. Whereas, for
    the the end of the read there is greater than 50% probability that the
    base is called incorrectly.
    
**** Assessing quality with FastQC
    :PROPERTIES:
    :CUSTOM_ID: assessing-quality-with-fastqc
    :END:
    
    Now that we understand what information is stored in a FASTQ file,
    let's talk about using that information to assess quality.
    
    This assessment of read quality is not performed manually; there are
    tools to help examine the quality metrics.  [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/][FastQC]] is one of the most
    common tools for this step of the workflow. It provides a modular set
    of analyses, with clear visualizations, to provide a quick impression
    of whether the data has any problems of which one should be aware of
    before proceeding with any further analysis.
    
    A few examples of assessments performed by FastQC are:
    + aggregate read quality information and plot box plots
    + levels of overrepresentation
    + GC%
    
    #+BEGIN_QUOTE
      FastQC has a really well documented [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/][manual page]] with [[http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/][more details]]
      about all the plots in the report. We recommend looking at [[http://bioinfo-core.org/index.php/9th_Discussion-28_October_2010][this post]]
      for more information on what bad plots look like and what they mean
      for your data.
    
      We also have a [[https://github.com/hbctraining/Intro-to-rnaseq-hpc-O2/raw/master/lectures/error_profiles_mm.pdf][slidedeck]] of error profiles for Illumina sequencing,
      where we discuss specific FASTQC plots and possible sources of these
      types of errors.
    #+END_QUOTE
    
    The "*Per base sequence quality*" plot is the most commonly used one and
    it provides the distribution of quality scores across all bases at each
    position in the reads.
    | [[./00Data/T14Data/FastQC_seq_qual.png]] |
*** Expression quantification
   :PROPERTIES:
   :CUSTOM_ID: expression-quantification
   :END:
   
   Once it has been determined that the read quality is good, the next step
   is to quantify gene expression.
   | [[./00Data/T14Data/rnaseq_salmon_workflow.png]] |
   Tools that have been found to be most accurate for this step in the
   analysis are referred to as lightweight alignment tools, which include
   [[https://pachterlab.github.io/kallisto/about][Kallisto]], [[http://www.nature.com/nbt/journal/v32/n5/full/nbt.2862.html][Sailfish]] and [[https://combine-lab.github.io/salmon/][Salmon]]; each working slightly different from
   one another. Salmon and Kallisto are equally good choices with similar
   performance metrics for speed and accuracy.
   
   Common to all of these tools is that *base-to-base alignment of the
   reads to the reference genome is avoided*, which is the time- and
   memory-consuming function of splice-aware alignment tools such as STAR
   and HISAT2. The lightweight alignment tools *provide quantification
   estimates much faster* (typically more than 20 times faster) with
   *improvements in accuracy* [[[https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0734-x][10.1186]]].  These transcript expression
   estimates, often referred to as 'pseudocounts' or 'abundance
   estimates', can be aggregated to the gene level for use with
   differential gene expression tools like [[http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html][DESeq2]] or the estimates can be
   used directly for splice-isoform differential expression using a tool
   like [[http://www.biorxiv.org/content/biorxiv/early/2016/06/10/058164.full.pdf][Sleuth]].
   
*** Expression data - Normalization and QC
   :PROPERTIES:
   :CUSTOM_ID: expression-data-normalization-and-qc
   :END:
   
   Once expression is quantified and counts are generated, the next step is
   more QC! The next few steps in the analysis are shown in the flowchart
   below.
   | [[./00Data/T14Data/de_workflow_salmon_qc.png]] |
**** Normalization of count data
    :PROPERTIES:
    :CUSTOM_ID: normalization-of-count-data
    :END:
    
    The first step in the DE analysis workflow is count normalization, which
    is necessary to make accurate comparisons of gene expression between
    samples.
    
    The counts of mapped reads for each gene is proportional to the
    expression of RNA ("interesting") in addition to many other factors
    ("uninteresting"). Normalization is the process of scaling raw count
    values to account for the "uninteresting" factors. In this way the
    expression levels are more comparable between and within samples.
    
    The main factors often considered during normalization are:
    
    - *Sequencing depth:* Accounting for sequencing depth is necessary for
      comparison of gene expression between samples. In the example below,
      each gene appears to have doubled in expression in /Sample A/
      relative to /Sample B/, however this is a consequence of /Sample A/
      having double the sequencing depth.
    | [[./00Data/T14Data/normalization_methods_depth.png]] |
      #+BEGIN_QUOTE
        NOTE: In the figure above, each pink and green rectangle
        represents a read aligned to a gene. Reads connected by dashed
        lines connect a read spanning an intron.
      #+END_QUOTE
    
    - *Gene length:* Accounting for gene length is necessary for comparing
      expression between different genes within the same sample. In the
      example, /Gene X/ and /Gene Y/ have similar levels of expression,
      but the number of reads mapped to /Gene X/ would be many more than
      the number mapped to /Gene Y/ because /Gene X/ is longer.
      | [[./00Data/T14Data/normalization_methods_length.png]] |
    - *RNA composition:* A few highly differentially expressed genes
      between samples, differences in the number of genes expressed
      between samples, or presence of contamination can skew some types of
      normalization methods. Accounting for RNA composition is recommended
      for accurate comparison of expression between samples, and is
      particularly important when performing differential expression
      analyses [[[https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-10-r106][10.1186]]].
    
      In the example, if we were to divide each sample by the total number
      of counts to normalize, the counts would be greatly skewed by the DE
      gene, which takes up most of the counts for /Sample A/, but not
      /Sample B/. Most other genes for /Sample A/ would be divided by the
      larger number of total counts and appear to be less expressed than
      those same genes in /Sample B/.
      | [[./00Data/T14Data/normalization_methods_composition.png]] |
    *While normalization is essential for differential expression analyses, it is also necessary for QC, exploratory data analysis, visualization of data, and whenever you are exploring or comparing counts between or within samples.*
    
    #+BEGIN_QUOTE
      *Common normalization methods*
    
      Several common normalization methods exist to account for these
      differences:
    
      | Normalization method                                                                  | Description                                                                                                                  | Accounted factors                                  | Recommendations for use                                                                                               |
      |---------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------|
      | *CPM* (counts per million)                                                            | counts scaled by total number of reads                                                                                       | sequencing depth                                   | gene count comparisons between replicates of the same samplegroup; *NOT for within sample comparisons or DE analysis* |
      | *TPM* (transcripts per kilobase million)                                              | counts per length of transcript (kb) per million reads mapped                                                                | sequencing depth and gene length                   | gene count comparisons within a sample or between samples of the same sample group; *NOT for DE analysis*             |
      | *RPKM/FPKM* (reads/fragments per kilobase of exon per million reads/fragments mapped) | similar to TPM                                                                                                               | sequencing depth and gene length                   | gene count comparisons between genes within a sample; *NOT for between sample comparisons or DE analysis*             |
      | DESeq2's *median of ratios* [[[https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-10-r106][1]]]                                                       | counts divided by sample-specific size factors determined by median ratio of gene counts relative to geometric mean per gene | sequencing depth and RNA composition               | gene count comparisons between samples and for *DE analysis*; *NOT for within sample comparisons*                     |
      | EdgeR's *trimmed mean of M values (TMM)* [[[https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-3-r25][2]]]                                          | uses a weighted trimmed mean of the log expression ratios between samples                                                    | sequencing depth, RNA composition, and gene length | gene count comparisons between and within samples and for *DE analysis*                                               |
    
      /NOTE:/ [[http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/][This video by StatQuest]] shows in more detail why TPM should
      be used in place of RPKM/FPKM if needing to normalize for sequencing
      depth and gene length.
    #+END_QUOTE
**** Quality Control
    :PROPERTIES:
    :CUSTOM_ID: quality-control
    :END:
    
    The next step in the differential expression workflow is QC, which
    includes sample-level and gene-level steps to perform QC checks on the
    count data to help us ensure that the samples/replicates look good and
    to help identify problematic expression trends and
    outliers. Normalized counts are utilized for this step.
    
***** Sample-level QC
     :PROPERTIES:
     :CUSTOM_ID: sample-level-qc
     :END:
     
     A useful initial step in an RNA-seq analysis is often to assess overall
     similarity between samples:
     
     - Which samples are similar to each other, which are different?
     - Does this fit to the expectation from the experiment's design?
     - What are the major sources of variation in the dataset?
     
     Sample-level QC allows us to see how well our replicates cluster
     together, as well as, observe whether our experimental condition
     represents the major source of variation in the data. Performing
     sample-level QC can also identify any sample outliers, which may need to
     be explored to determine whether they need to be removed prior to DE
     analysis.
     
     The 2 main methods utilized for this type of QC are Principal Component
     Analysis (PCA) and Hierarchical Clustering.
     | [[./00Data/T14Data/sample_qc.png]] |
***** Gene-level QC
     :PROPERTIES:
     :CUSTOM_ID: gene-level-qc
     :END:
    
    In addition to examining how well the samples/replicates cluster
    together, there are a few more QC steps. Prior to differential
    expression analysis it is beneficial to omit genes that have little or
    no chance of being detected as differentially expressed. This will
    increase the power to detect differentially expressed genes. The genes
    omitted fall into three categories:
    
    - Genes with zero counts in all samples
    - Genes with an extreme count outlier
    - Genes with a low mean normalized counts
    | [[./00Data/T14Data/gene_filtering.png]] |
    *Some statistical tools, e.g. DESeq2, used for identifying differentially expressed genes will perform this filtering by default; however other tools, e.g. EdgeR, will not.*
    
*** Count modeling and statistical analysis
   :PROPERTIES:
   :CUSTOM_ID: count-modeling-and-statistical-analysis
   :END:
   
   The final step in the differential expression analysis workflow is
   fitting the counts to a model and performing the statistical test for
   differentially expressed genes. In this step we essentially want to
   determine whether the mean expression levels of different sample
   groups are significantly different.
   | [[./00Data/T14Data/de_theory.png]] |
   /Image credit: Paul Pavlidis, UBC/
   
**** Some highlights of RNA-seq count data
    :PROPERTIES:
    :CUSTOM_ID: some-highlights-of-rna-seq-count-data
    :END:
    
    - there are a low number of counts associated with a large proportion
      of genes
    - there is no upper limit for expression (large dynamic range)
    - the negative binomial model has been determined to be the best fit
      for the count distribution for RNA-seq data where there is a lot of
      variance between the replicates and mean < variance
    
**** Tools for statistical analysis
    :PROPERTIES:
    :CUSTOM_ID: tools-for-statistical-analysis
    :END:
    
    There are a number of software packages that have been developed for
    differential expression analysis of RNA-seq data. A few tools are
    generally recommended as best practice, e.g. *[[https://bioconductor.org/packages/release/bioc/html/DESeq2.html][DESeq2]]* and *[[https://bioconductor.org/packages/release/bioc/html/edgeR.html][EdgeR]]*.
    Both these R packages use the negative binomial model, employ similar
    methods, and typically, yield similar results. They are pretty
    stringent, and have a good balance between sensitivity and specificity
    (reducing both false positives and false negatives).
    
    *[[https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29][Limma-Voom]]* is another set of tools often used together for DE
    analysis, but this method may be less sensitive for small sample
    sizes. This method is recommended when the number of biological
    replicates per group grows large (> 20).
    
    /[[https://mikelove.wordpress.com/2016/09/28/deseq2-or-edger/][Further reading about DGE tool comparisons]]/.
    
**** Multiple test correction
    :PROPERTIES:
    :CUSTOM_ID: multiple-test-correction
    :END:
    
    The output of any of these analysis methods is a p-value as well as a
    value assigning statistical significance after multiple test correction,
    and the second value is what should be used when creating lists of genes
    that are differentially expressed.
    
    Each p-value returned is the result of a single test (single gene). If
    we used the =p-value= directly with a significance cut-off of p < 0.05,
    that means there is a 5% chance it is a false positive and the more
    genes we test, the more we inflate the false positive rate. For example,
    if we test 20,000 genes for differential expression, at p < 0.05 we
    would expect to find 1,000 genes by chance. If we found 3000 genes to be
    differentially expressed total, roughly one third of our genes are false
    positives. We would not want to sift through our "significant" genes to
    identify which ones are true positives.
    
    A few common methods to correct for multiple testing are listed below:
    
    - *Bonferroni:* The adjusted p-value is calculated by: p-value * m (m =
      total number of tests). *This is a very conservative approach with a
      high probability of false negatives*, so is generally not recommended.
    - *FDR/Benjamini-Hochberg:* Benjamini and Hochberg (1995) defined the
      concept of FDR and created an algorithm to control the expected FDR
      below a specified level given a list of independent p-values. *An
      interpretation of the BH method for controlling the FDR is implemented
      in DESeq2 in which we rank the genes by p-value, then multiply each
      ranked p-value by m/rank*.
    - *Q-value / Storey method:* The minimum FDR that can be attained when
      calling that feature significant. For example, if gene X has a q-value
      of 0.013 it means that 1.3% of genes that show p-values at least as
      small as gene X are false positives
    
** *Single-cell RNA-Seq Analysis Workflow*
  :PROPERTIES:
  :CUSTOM_ID: single-cell-rna-seq-analysis-workflow
  :END:
  | [[./00Data/T14Data/sc_workflow.png]] |
*** Count matrix generation
   :PROPERTIES:
   :CUSTOM_ID: count-matrix-generation
   :END:
   
   The scRNA-seq method will determine how to generate the count matrix
   using technology-specific methods to parse the barcodes and UMIs from
   the sequencing reads so as to delineate the cells and the transcripts.
   
   "*[[https://github.com/vals/umis][umis]]* provides tools for estimating expression in RNA-seq data which performs sequencing of end tags of transcript, and incorporate molecular tags to correct for amplification bias."

   The steps in this process include the following:
   
   1. Formatting reads and filtering noisy cellular barcodes
   2. Demultiplexing the samples
   3. Pseudo-mapping to cDNAs
   4. Counting molecular identifiers
   | [[./00Data/T14Data/sc_collapsing_umis.png]] |
   The generation of the count matrix from the raw sequencing data follow
   the steps in the schematic below for many of the scRNA-seq methods.
   | [[./00Data/T14Data/sc_pre-QC_workflow.png]] |
   Following the generation of count matrix, the remaining steps can be
   performed using [[https://satijalab.org/seurat/#about-seurat][Seurat]], the R toolkit for single cell genomics. A
   tutorial for the remaining steps can be [[https://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html][found here]], and requires a
   good working knowledge of R.
   
*** Filtering
   :PROPERTIES:
   :CUSTOM_ID: filtering
   :END:
   
   Poor quality cells can be filtered out of the count matrix data before
   moving forward. Poor quality cells often have the following
   characteristics:
   - *a low number of genes or UMIs*
   - *high mitochondrial gene expression indicative of dying cells*
   
*** Clustering
   :PROPERTIES:
   :CUSTOM_ID: clustering
   :END:
   
   After removing the poor quality cells, the cells can now be clustered
   based on similarities in transcriptional activity, with the idea that
   the different cell types separate into the different clusters. The
   following steps can be followed to perform clustering:
   
   1. *Normalization and transformation* of the raw gene counts per cell to
      account for *differences in sequencing depth* per cell.
   2. Identification of high variance genes.
   3. *Regression of sources of unwanted variation* (e.g. number of UMIs
      per cell, mitochondrial transcript abundance, cell cycle phase).
   4. *Identification of the primary sources of heterogeneity* using
      principal component (PC) analysis and heatmaps.
   5. *Clustering cells* based on significant PCs.
   
   To visualize the clusters, there are a few different options that can
   be helpful, including t-distributed stochastic neighbor embedding
   (t-SNE), Uniform Manifold Approximation and Projection (UMAP), and
   PCA. The goals of these methods is to have similar cells closer
   together in low-dimensional space.
   | [[./00Data/T14Data/tSNE.png]] |
*** Marker identification
   :PROPERTIES:
   :CUSTOM_ID: marker-identification
   :END:
   
   After clustering, genes that are markers for different clusters can be
   used to help identify the cell type of each cluster. Finally, after
   identification of cell types, there are various types of analyses that
   can be performed depending on the goal of the experiment.
   | [[./00Data/T14Data/tSNE-labelled3.png]] |
** *Visualizing the Results of a DGE Experiment*
   :PROPERTIES:
   :CUSTOM_ID: visualizing-the-results-of-a-dge-experiment
   :END:

*** Plotting signicantly differentially expressed genes
    :PROPERTIES:
    :CUSTOM_ID: plotting-signicantly-differentially-expressed-genes
    :END:
    
    One way to visualize results would be to simply plot the expression
    data for a handful of genes across the various sample groups.
    
    This can be implemented in R (usually) for *multiple genes* of
    interest or a *single gene* using functions associated with 
    + the package used to perform the statistical analysis (e.g. DESeq2's =plotCounts()= function) or 
    + an external package created for this purpose (e.g. pheatmap, [[https://bioconductor.org/packages/release/bioc/html/DEGreport.html][DEGreport]]) or 
    + using the =ggplot2= package.
    
**** Plotting expression of a single gene across sample groups:
     :PROPERTIES:
     :CUSTOM_ID: plotting-expression-of-a-single-gene-across-sample-groups
     :END:
     | [[./00Data/T14Data/plotCounts_ggrepel.png]] |
**** Plotting expression of multiple genes across sample groups :
     :PROPERTIES:
     :CUSTOM_ID: plotting-expression-of-multiple-genes-across-sample-groups
     :END:
     
     One way to visualize results would be to simply plot the expression
     data for a handful of genes across the various sample groups.
     
     The plot below displays the top 20 significantly differentially
     expressed genes. Please note that the normalized counts on the Y axis
     are logged (log10) to ensure that the any large differences in
     expression are plotted without compromising the quality of the
     visualization.
     | [[./00Data/T14Data/sig_genes_melt.png]] |
*** Heatmap
    :PROPERTIES:
    :CUSTOM_ID: heatmap
    :END:
    
    In addition to plotting subsets, we could also extract the normalized
    values of /all/ the significant genes and plot a heatmap of their
    expression using =pheatmap()=.
         | [[./00Data/T14Data/sigOE_heatmap.png]] |
    In this heatmap Z-scores are calculated for each row (each gene) and
    these are plotted instead of the normalized expression values; this
    ensures that the expression patterns/trends that we want to visualize
    are not overwhelmed by the expression values.
    
    #+BEGIN_QUOTE
      Z-scores are computed on a gene-by-gene basis by subtracting the
      mean and then dividing by the standard deviation. The Z-scores
      are computed *after the clustering*, so that it only affects the
      graphical aesthetics and the color visualization is improved.
    #+END_QUOTE
    
*** Volcano plot
    :PROPERTIES:
    :CUSTOM_ID: volcano-plot
    :END:
    
    The above plot would be great to look at the expression levels of a
    good number of genes, but for more of a global view there are other
    plots. A commonly used one is a volcano plot; in which you have the
    log transformed adjusted p-values are plotted on the y-axis and log2
    fold change values on the x-axis.
         | [[./00Data/T14Data/volcanoplot-2.png]] |
*** DEGreport
   :PROPERTIES:
   :CUSTOM_ID: degreport
   :END:
   
   If you do use the DESeq2 package for differential expression analysis,
   the package 'DEGreport' has a lot of great functions to draw a lot of
   the above plots in addition to several others. Some examples are
   available in [[https://bioconductor.org/packages/release/bioc/vignettes/DEGreport/inst/doc/DEGreport.html][this vignette]], and some of them are shown below.
   
   *Plot 1:* An easy and clean way to visualize expression of genes of
   interest.
   | [[./00Data/T14Data/degreport_ind_genes.png]] |
   *Plot 2:* When performing DE analysis on several groups, e.g. a time
   course experiment, grouping together genes that have similar patterns
   of expression and visualizing these patterns can be very helpful. The
   =degPatterns()= function in the DEGreport package performs the
   analysis and creates a display with this information.
   | [[./00Data/T14Data/DEGpatterns.png]] |
   /Images adapted from doi: [[https://f1000research.com/articles/6-1976/v2][10.12688/f1000research.12093.2]]./
   
   #+BEGIN_QUOTE
     In addition to displaying the patterns, =degPatterns()= outputs a list
     to enable the user to extract the genes in each grouping.
   #+END_QUOTE
** *References*
  + *[[https://github.com/hbctraining/rnaseq-cb321][RNASeq]] Tutorials Prepared by the [[https://github.com/hbctraining][Harvard Chan Bioinformatics Core]]*
  + This lesson has been developed by members of the teaching team at
    the Harvard Chan Bioinformatics Core (HBC). These are open access
    materials distributed under the terms of the Creative Commons
    Attribution license (CC BY 4.0), which permits unrestricted use,
    distribution, and reproduction in any medium, provided the
    original author and source are credited.
  + *NOTE01:* /The Single-cell RNA-Seq Analysis Workflow lesson was adapted from [[https://github.com/marypiper/WIB_scRNA-seq#wib_scrna-seq][Dr. Mary Piper's presentation]] for the [[https://www.meetup.com/boston-area-womens-bioinformatics/][Boston-area Women's Bioinformatics Meetup]]./
  + *NOTE02:* /The Visualizing the Results of a DGE Experiment Materials and hands-on activities were adapted from [[http://www.bioconductor.org/help/workflows/rnaseqGene/#de][RNA-seq workflow]] on the Bioconductor website./
* 
| *Navigation:*             | *[[https://github.tamu.edu/DigitalBiology/BIOL647_Digital_Biology_2021/wiki][Home]]*                                                                       |
| *Author: [[raramayo@tamu.edu][Rodolfo Aramayo]]* | *License: [[http://creativecommons.org/licenses/by-nc-sa/4.0/][All content produced in this site is licensed by: CC BY-NC-SA 4.0]]* |
